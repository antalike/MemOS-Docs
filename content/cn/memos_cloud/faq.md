---
title: FAQs
desc: 我们集中整理了使用 MemOS 过程中最常见的困惑，不用到处翻资料，就能快速找到答案。
---


### Q：MemOS 和普通 RAG 框架有什么区别？

| **对比维度** | **RAG** | **MemOS** | **MemOS 的优势** |
| --- | --- | --- | --- |
| 精准度 | 语料越多，噪声越大 |    通过生产阶段的抽取、图式化/关系建模，再配合调度与生命周期管理，形成结构化组织，记忆条理更清晰<br>    <br>   能够基于用户反馈驱动自我进化 | **更准**：减少噪声，降低幻觉 |
| 结果组织 | 直接拿原文段落，内容冗余 | 将原始信息加工为记忆，提炼成事实/偏好等单元，内容更短、更纯粹 | **更省**：同等信息量下更少 token |
| 搜索范围 | 每次都在全量语料里搜，语料越大越慢 | 记忆动态更新，分层管理，逐层召回 | **更快**：避免全局扫描，小范围命中 |
| 理解力 | 不能从用户历史对话中沉淀偏好（无个性化），仅依赖静态知识库的相似度匹配 | 会自动提取记忆做偏好建模，并在召回时转化为可执行的指令，让模型真正理解到位。 | **更懂**：回答更贴近真实需求 |


### Q：MemOS 可以和已有 RAG 或知识图谱结合吗？

可以。  
RAG 专注于 **事实检索与知识增强**，让模型“知道世界上有什么”；  
MemOS 专注于 **状态管理与连续记忆**，让模型“知道你是谁、你想要什么”。

两者结合后能形成互补的智能结构：

> 🧠 **RAG 提供外部知识，MemOS 提供内在记忆。**  
> 前者让模型更聪明，后者让模型更懂你。

在实践中，**MemOS 的记忆单元** 可以与 **RAG 的向量召回层** 直接对接，也能调用外部知识图谱。  
区别在于——RAG 管理的是 **静态事实**，而 MemOS 管理的是 **随时间演化的动态记忆**。

换句话说：  
- **RAG** 让模型更像百科全书；  
- **MemOS** 让模型更像你长期相处的助手。  

当两者融合时，AI 就既能“知道世界”，也能“理解你”。


### Q：MemOS如何工作？

我们的云服务平台为您提供了两个核心接口：

`addMessage` —— 把原始信息（用户与 AI 的对话、用户在APP上的操作日志 / 行动轨迹等）交给我们，我们自动加工并存储记忆；

`searchMemory` —— 在后续对话中召回相关记忆并完成指令拼接（可选），让 AI 回答更贴近用户需求。


### Q：MemOS核心功能有哪些？

*   **用户/Agent记忆管理**：支持长期保存用户与 AI 的交互内容，并能在多代理协同场景下共享或隔离记忆，保证任务连续。
    

*   **动态分层调度**：区别于静态 RAG，MemOS 会根据任务优先级在激活记忆、明文记忆之间动态切换，避免全局扫描，让调用更快更准。
    

*   **个性化偏好建模**：自动从历史交互中抽取用户偏好，并在实时生成中补全指令，使模型输出更贴近用户习惯。
    

*   **记忆生命周期治理**：通过合并、压缩、归档机制避免记忆膨胀，长期保持高效而稳定的知识库。
    

*   **开发者友好 API**：开放统一接口，既能调用开源框架，也能直接接入云服务，集成成本低。
    

*   **跨平台一致性**：无论本地部署还是云端托管，都能保持一致的记忆调度行为和数据格式。
    

*   **托管服务支持**：提供云服务托管，内置监控、弹性扩展，降低运维成本。
    

*   **成本节约**：通过记忆加工与优先级调度，只注入必要信息，比直接拼接原文更节省 token。
    

### Q：如何评估使用 MemOS 带来的 ROI？

典型指标包括：token 消耗下降（更省）、输出相关度提高（更准）、用户留存率提升（更懂）、知识沉淀率（多少被长期固化）。


### Q：如何进一步提升MemOS在具体业务场景中的的效果？

您可以联系我们做商业化定制（最快最好），另一方面MemOS本身开源，您的团队可深入研究自行改造（有理解成本可能会走弯路）


### Q：MemOS 是否支持私有化部署？
支持


### Q：生命周期和调度有什么关系？ 
生命周期负责“记忆单元的状态流转”，调度负责“在任意时刻选中合适的记忆单元并送入模型”。两者互补，但不等价


### Q：MemOS 如何避免记忆膨胀？
通过合并、压缩、归档机制：低价值记忆被下调频率，高价值记忆被合并或沉淀。最终保证存储和推理都保持高效。


<br>

**Q：KV-Cache 和激活记忆是一回事吗？**  
不是。KV-Cache 是底层计算实现，激活记忆是业务层概念。当前激活记忆主要依托 KV-Cache，但未来也可能有其他实现方式。


### Q：MemOS 会不会拖慢推理？
不会。调度器异步运行，并采用缓存稳定策略，保证记忆更新与调用的平衡。实际测试中，延迟提升通常在可接受范围内。


### Q：如果用户请求的信息已经很近，比如“昨天做的事”，还需要调度吗？
是的。调度不仅仅解决“找得到”，更解决“快而准、少冗余”。即使时间接近，调度器依然会评估是否需要融合成完整上下文。


### Q：MemOS服务了哪些产品？
目前MemOS 已在多个领域落地应用，包括【陪伴、游戏、旅游、运营商、金融证券、制造业与教育科研】等。合作伙伴涵盖多家头部央国企与行业领先团队，相关项目已在具身智能、AI客服、知识管理、智能投顾、生产运维、AI伴学等场景中验证了记忆驱动的成效。
有些项目还在联合打磨阶段，暂不方便公开细节，但后续会陆续分享更具体的案例故事～
